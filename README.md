# Motion-Based-Game-Control

Motion-Based-Game-Control is aimed at enhancing the video gaming experience by enabling players to use their body movements as game controls. This project seeks to make gaming more accessible and immersive by using computer vision techniques and machine learning models to translate physical gestures into game actions. 


## Project Demo Video

## Alpha Release

## Major Features
**Gesture Recognition**: Utilizes existing human pose and hand gesture recognition techniques to interpret player movements accurately.  
**Real-Time Processing**: Ensures rapid processing of camera data to minimize delay, maintaining an immersive gaming experience.  
**Input Translation**: Maps recognized gestures to predefined keyboard inputs, enabling intuitive game control without physical devices.  
**Game Integration**: Designed to be compatible with a wide range of games, allowing for a broad application of the technology.  


## Stretch Goals



## Additional Features



## Technology Stack
**OpenCV**: For video processing and motion recognition.  
**MediaPipe**: Utilized for robust body and gesture recognition models.  
**PyInput**: Converts gesture data into simulated keyboard inputs.  
**PyGame/PyQt**: For testing integration with games and possibly for developing a user interface.  



## Installation (Build/Run For Users)

```
pip install -r requirements.txt
```
